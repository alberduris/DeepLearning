{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN - Tensorflow API - Static - Predicting binary sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_OBSERVATIONS = 10000\n",
    "\n",
    "NUM_STEPS = 10 #Number of truncated backprop steps\n",
    "BATCH_SIZE = 3\n",
    "NUM_CLASSES = 2 #Binary problem\n",
    "\n",
    "STATE_SIZE = 16\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "DISPLAY_FREQ = NUM_OBSERVATIONS//NUM_STEPS//BATCH_SIZE//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With current configuration 333 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "print('With current configuration %d batches per epoch' % (NUM_OBSERVATIONS//NUM_STEPS//BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gen data:**\n",
    "- Input sequence (X): At time step t, Xt has a 50% chance of being 1 (and a 50% chance of being 0). E.g., X might be [1, 0, 0, 1, 1, 1 â€¦ ].\n",
    "- Output sequence (Y):At time step t, Yt has a base 50% chance of being 1 (and a 50% base chance to be 0). The chance of Yt being 1 is increased by 50% (i.e., to 100%) if Xt-3 is 1, and decreased by 25% (i.e., to 25%) if Xt-8 is 1. If both Xt-3 and Xt-8 are 1 the chance of Yt being 1 is 50% + 50% - 25%= 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=NUM_OBSERVATIONS):\n",
    "    X = np.array(np.random.choice(2,size=(size,))) #Random binary array of size 'size'\n",
    "    Y = [] #Targets\n",
    "    \n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1: #First dependency at t-3\n",
    "            threshold += 0.5 \n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "            \n",
    "    return X,np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data,batch_size,num_steps):\n",
    "    raw_x,raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    #Partition data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length//batch_size\n",
    "    \n",
    "    data_x = np.zeros(shape=(batch_size,batch_partition_length),dtype=np.int32)\n",
    "    data_y = np.zeros(shape=(batch_size,batch_partition_length),dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length*i : batch_partition_length*(i+1)]\n",
    "        data_y[i] = raw_y[batch_partition_length*i : batch_partition_length*(i+1)]\n",
    "        \n",
    "    #Further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:,i * num_steps:(i+1) * num_steps]\n",
    "        y = data_y[:,i * num_steps:(i+1) * num_steps]\n",
    "        yield(x,y)\n",
    "        \n",
    "def gen_epochs(num_epochs,batch_size,num_steps):\n",
    "    for i in range(num_epochs):\n",
    "        yield gen_batch(gen_data(),batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Take a look at how data generating functions works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 1, 1, 1, 0]), array([1, 1, 0, 0, 1, 1, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = gen_data(10)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New batch:\n",
      "[[0 0 0 0 1 0 1 1 1 0]]\n",
      "[[1 1 0 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "for x,y in gen_batch([X,Y],batch_size=1,num_steps=NUM_STEPS):\n",
    "    print('New batch:')\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Formally, the model is <a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html#model_architecture\">Click!</a> <- Original post\n",
    "\n",
    "Diagram of the model:\n",
    "\n",
    "<a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html#model_architecture\"><img src=\"https://r2rt.com/static/images/BasicRNNLabeled.png\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **x placeholder** will hold our random binary array input\n",
    "- **y placeholder** will hold our labels array target\n",
    "- **init state placeholder** will hold the state for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[BATCH_SIZE,NUM_STEPS],dtype=tf.int32,name='input_placeholder')\n",
    "y = tf.placeholder(shape=[BATCH_SIZE,NUM_STEPS],dtype=tf.int32,name='labels_placeholder')\n",
    "init_state = tf.zeros([BATCH_SIZE,STATE_SIZE],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_placeholder:0' shape=(3, 10) dtype=int32>,\n",
       " <tf.Tensor 'labels_placeholder:0' shape=(3, 10) dtype=int32>,\n",
       " <tf.Tensor 'zeros:0' shape=(3, 16) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Inputs\n",
    "\n",
    "Turn x placeholder into a list of one-hot tensors\n",
    "\n",
    "**rnn_inputs** is a list of num_steps tensors with shape [batch_size,num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_one_hot = tf.one_hot(x,NUM_CLASSES)\n",
    "rnn_inputs = tf.unstack(x_one_hot,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'one_hot:0' shape=(3, 10, 2) dtype=float32>,\n",
       " [<tf.Tensor 'unstack:0' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:1' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:2' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:3' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:4' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:5' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:6' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:7' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:8' shape=(3, 2) dtype=float32>,\n",
       "  <tf.Tensor 'unstack:9' shape=(3, 2) dtype=float32>])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot,rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of rnn_cell\n",
    "\n",
    "This is very similar to the 'call' method on Tensorflow's BasicRNNCell. \n",
    "See: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1213\n",
    "\n",
    "According to their documentation:<br>\n",
    "Run the cell and add its inputs to its outputs.<br>\n",
    "\n",
    "It looks like:\n",
    "<a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\"><img src=\"https://r2rt.com/static/images/NH_VanillaRNNcell.png\" width=\"400px\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable(name='W',shape=[NUM_CLASSES + STATE_SIZE, STATE_SIZE])\n",
    "    b = tf.get_variable(name='b',shape=[STATE_SIZE],initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "def rnn_cell(rnn_input,state):\n",
    "    with tf.variable_scope('rnn_cell',reuse=True):\n",
    "        W = tf.get_variable(name='W',shape=[NUM_CLASSES + STATE_SIZE, STATE_SIZE])\n",
    "        b = tf.get_variable(name='b',shape=[STATE_SIZE],initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "    #concat(rnn_input,state) => Prior state & Current Input on the image\n",
    "    #W, bias and tanh are pretty clear in the image\n",
    "    return tf.tanh(tf.matmul(tf.concat(values=[rnn_input,state],axis=1),W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api.\n",
    "See: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L1092\n",
    "\n",
    "According to their documentation:<br>\n",
    "Creates a recurrent neural network specified by RNNCell `cell`.\n",
    "\n",
    "It looks like:\n",
    "\n",
    "<a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\"><img src=\"https://r2rt.com/static/images/NH_ComposedRNNcells.png\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = init_state #Initialize state (left dotted square on image)\n",
    "rnn_outputs = [] #Create a list as placeholder for the outputs (top dotted squares in image)\n",
    "\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input=rnn_input,state=state) #Create a RNN cell and store the output state\n",
    "    rnn_outputs.append(state) #Append it to the list\n",
    "final_state = rnn_outputs[-1] #The final state is the last output (top right dotted square on the image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions, loss, training step\n",
    "\n",
    "Predictions will be the result of **softmax** to the **logits**. **Logits** will be the result of matrix multiplication with **Wout** and **bout**.\n",
    "\n",
    "Because of the steps, instead of one, we will have several **losses**, one for each step. **Total loss** will be just the mean of every losses.\n",
    "\n",
    "As **optimizer** we'll be using the **Adagradoptimizer**, to do de backpropagation, feel free to experiment with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Predictions##\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W',[STATE_SIZE,NUM_CLASSES])\n",
    "    b = tf.get_variable('b',[NUM_CLASSES],initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "logits = [tf.matmul(rnn_output,W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "\n",
    "\n",
    "##Losses##\n",
    "y_as_list = tf.unstack(y,num=NUM_STEPS,axis=1) #Turn our y placeholder into a list of labels\n",
    "#One loss for each step, that is, for each <logit and target>\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label,logits=logit) for logit,label in zip(logits,y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "##Optimizer##\n",
    "train_step = tf.train.AdagradOptimizer(LEARNING_RATE).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(num_epochs,state_size=4):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        \n",
    "        for idx,epoch in enumerate(gen_epochs(num_epochs,BATCH_SIZE,NUM_STEPS)):\n",
    "            training_loss = 0\n",
    "            training_state = np.random.normal(size=(BATCH_SIZE,STATE_SIZE)) #Random initiate state\n",
    "        \n",
    "            print('Epoch %d'%idx)\n",
    "            \n",
    "            for step,(X,Y) in enumerate(epoch):\n",
    "                \n",
    "                feed_dict = {x:X,y:Y,init_state:training_state}\n",
    "                tr_losses,training_loss_,training_state,_ = sess.run([losses,total_loss,final_state,train_step],feed_dict)\n",
    "                training_loss += training_loss_\n",
    "                \n",
    "                if(step % 100 == 0 and step > 0):\n",
    "                    print('Average loss at step %d for last 250 steps: %.3f'%(step,training_loss/100))\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "                \n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Average loss at step 100 for last 250 steps: 0.546\n",
      "Average loss at step 200 for last 250 steps: 0.503\n",
      "Average loss at step 300 for last 250 steps: 0.504\n",
      "Epoch 1\n",
      "Average loss at step 100 for last 250 steps: 0.495\n",
      "Average loss at step 200 for last 250 steps: 0.494\n",
      "Average loss at step 300 for last 250 steps: 0.490\n",
      "Epoch 2\n",
      "Average loss at step 100 for last 250 steps: 0.493\n",
      "Average loss at step 200 for last 250 steps: 0.491\n",
      "Average loss at step 300 for last 250 steps: 0.484\n",
      "Epoch 3\n",
      "Average loss at step 100 for last 250 steps: 0.486\n",
      "Average loss at step 200 for last 250 steps: 0.492\n",
      "Average loss at step 300 for last 250 steps: 0.482\n",
      "Epoch 4\n",
      "Average loss at step 100 for last 250 steps: 0.480\n",
      "Average loss at step 200 for last 250 steps: 0.476\n",
      "Average loss at step 300 for last 250 steps: 0.475\n",
      "Epoch 5\n",
      "Average loss at step 100 for last 250 steps: 0.487\n",
      "Average loss at step 200 for last 250 steps: 0.481\n",
      "Average loss at step 300 for last 250 steps: 0.483\n",
      "Epoch 6\n",
      "Average loss at step 100 for last 250 steps: 0.491\n",
      "Average loss at step 200 for last 250 steps: 0.471\n",
      "Average loss at step 300 for last 250 steps: 0.491\n",
      "Epoch 7\n",
      "Average loss at step 100 for last 250 steps: 0.489\n",
      "Average loss at step 200 for last 250 steps: 0.482\n",
      "Average loss at step 300 for last 250 steps: 0.485\n",
      "Epoch 8\n",
      "Average loss at step 100 for last 250 steps: 0.472\n",
      "Average loss at step 200 for last 250 steps: 0.468\n",
      "Average loss at step 300 for last 250 steps: 0.469\n",
      "Epoch 9\n",
      "Average loss at step 100 for last 250 steps: 0.480\n",
      "Average loss at step 200 for last 250 steps: 0.477\n",
      "Average loss at step 300 for last 250 steps: 0.479\n"
     ]
    }
   ],
   "source": [
    "training_losses = train_network(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLUyLCRJrQwLSVKr/w/I/Gp5YE62sgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ae273eb780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.scatter(x=np.arange(0,len(training_losses)),y=training_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with NUM_STEPS to capture long-term dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUM_STEPS = 1\n",
    "\n",
    "Average loss at step 3300 for last 250 steps: 0.630\n",
    "\n",
    "### NUM_STEPS = 2\n",
    "\n",
    "Average loss at step 1600 for last 250 steps: 0.600\n",
    "\n",
    "### NUM_STEPS = 3\n",
    "\n",
    "Average loss at step 1100 for last 250 steps: 0.619\n",
    "\n",
    "### NUM_STEPS = 4\n",
    "\n",
    "Average loss at step 800 for last 250 steps: 0.530\n",
    "\n",
    "### NUM_STEPS = 5\n",
    "\n",
    "Average loss at step 600 for last 250 steps: 0.529\n",
    "\n",
    "### NUM_STEPS = 7\n",
    "\n",
    "Average loss at step 400 for last 250 steps: 0.541\n",
    "\n",
    "### NUM_STEPS = 8\n",
    "\n",
    "Average loss at step 400 for last 250 steps: 0.576\n",
    "\n",
    "### NUM_STEPS = 9\n",
    "\n",
    "Average loss at step 400 for last 250 steps: 0.514\n",
    "\n",
    "### NUM_STEPS = 10 & STATE_SIZE = 16 & NUM_EPOCHS = 10 (Not learning with state size 4 and 1 epoch)\n",
    "\n",
    "Average loss at step 300 for last 250 steps: 0.479"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
