{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN - Tensorflow API - Dynamic - Predicting binary sequences\n",
    "\n",
    "In this notebook we will implement the **same** model of ``\"VanillaRNN_Tensorflow.ipynb\"`` but using the **Tensorflow RNN Dynamic API**\n",
    "\n",
    "In the other two notebooks, we added every node for every timestep to the graph before execution. This is called “static” construction. \n",
    "\n",
    "We could also let Tensorflow dynamically create the graph at execution time, which can be more efficient. \n",
    "\n",
    "To do this, instead of using a list of tensors (of length num_steps and shape  [batch_size, features]), we keep everything in a single 3-dimnesional tensor of shape  [batch_size, num_steps, features], and use Tensorflow’s ``dynamic_rnn`` function. \n",
    "\n",
    "<a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html#using-a-dynamic-rnn\">[Ref]</a>\n",
    "\n",
    "Only four cells are different, they will be distinguished with a separator line like this ▽\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_OBSERVATIONS = 10000\n",
    "\n",
    "NUM_STEPS = 10 #Number of truncated backprop steps\n",
    "BATCH_SIZE = 3\n",
    "NUM_CLASSES = 2 #Binary problem\n",
    "\n",
    "STATE_SIZE = 16\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "DISPLAY_FREQ = NUM_OBSERVATIONS//NUM_STEPS//BATCH_SIZE//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With current configuration 333 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "print('With current configuration %d batches per epoch' % (NUM_OBSERVATIONS//NUM_STEPS//BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gen data:**\n",
    "- Input sequence (X): At time step t, Xt has a 50% chance of being 1 (and a 50% chance of being 0). E.g., X might be [1, 0, 0, 1, 1, 1 … ].\n",
    "- Output sequence (Y):At time step t, Yt has a base 50% chance of being 1 (and a 50% base chance to be 0). The chance of Yt being 1 is increased by 50% (i.e., to 100%) if Xt-3 is 1, and decreased by 25% (i.e., to 25%) if Xt-8 is 1. If both Xt-3 and Xt-8 are 1 the chance of Yt being 1 is 50% + 50% - 25%= 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=NUM_OBSERVATIONS):\n",
    "    X = np.array(np.random.choice(2,size=(size,))) #Random binary array of size 'size'\n",
    "    Y = [] #Targets\n",
    "    \n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1: #First dependency at t-3\n",
    "            threshold += 0.5 \n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "            \n",
    "    return X,np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data,batch_size,num_steps):\n",
    "    raw_x,raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    #Partition data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length//batch_size\n",
    "    \n",
    "    data_x = np.zeros(shape=(batch_size,batch_partition_length),dtype=np.int32)\n",
    "    data_y = np.zeros(shape=(batch_size,batch_partition_length),dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length*i : batch_partition_length*(i+1)]\n",
    "        data_y[i] = raw_y[batch_partition_length*i : batch_partition_length*(i+1)]\n",
    "        \n",
    "    #Further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:,i * num_steps:(i+1) * num_steps]\n",
    "        y = data_y[:,i * num_steps:(i+1) * num_steps]\n",
    "        yield(x,y)\n",
    "        \n",
    "def gen_epochs(num_epochs,batch_size,num_steps):\n",
    "    for i in range(num_epochs):\n",
    "        yield gen_batch(gen_data(),batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Take a look at how data generating functions works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), array([1, 0, 1, 1, 0, 0, 1, 1, 0, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = gen_data(10)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New batch:\n",
      "[[0 0 0 1 1 0 1 0 0 1]]\n",
      "[[1 0 1 1 0 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "for x,y in gen_batch([X,Y],batch_size=1,num_steps=NUM_STEPS):\n",
    "    print('New batch:')\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Formally, the model is <a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html#model_architecture\">Click!</a> <- Original post\n",
    "\n",
    "Diagram of the model:\n",
    "\n",
    "<a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html#model_architecture\"><img src=\"https://r2rt.com/static/images/BasicRNNLabeled.png\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **x placeholder** will hold our random binary array input\n",
    "<img src=\"https://github.com/alberduris/DeepLearning/blob/master/RecurrentNeuralNetworks/R2RT%20-%20RNN%20Tensorflow%20tutorials/src/x_placeholder.png?raw=true\">\n",
    "\n",
    "- **y placeholder** will hold our labels array target\n",
    "<img src=\"https://github.com/alberduris/DeepLearning/blob/master/RecurrentNeuralNetworks/R2RT%20-%20RNN%20Tensorflow%20tutorials/src/y_placeholder.png?raw=true\">\n",
    "\n",
    "- **init state placeholder** will hold the state for each batch\n",
    "<img src=\"https://github.com/alberduris/DeepLearning/blob/master/RecurrentNeuralNetworks/R2RT%20-%20RNN%20Tensorflow%20tutorials/src/init_state_placeholder.PNG?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[BATCH_SIZE,NUM_STEPS],dtype=tf.int32,name='input_placeholder')\n",
    "y = tf.placeholder(shape=[BATCH_SIZE,NUM_STEPS],dtype=tf.int32,name='labels_placeholder')\n",
    "init_state = tf.zeros([BATCH_SIZE,STATE_SIZE],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'input_placeholder:0' shape=(3, 10) dtype=int32>,\n",
       " <tf.Tensor 'labels_placeholder:0' shape=(3, 10) dtype=int32>,\n",
       " <tf.Tensor 'zeros:0' shape=(3, 16) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RNN Inputs\n",
    "\n",
    "**rnn_inputs:** OneHot representation of the data\n",
    "\n",
    "Instead of using a list of tensors (of length num_steps and shape  [batch_size, features]), we keep everything in:\n",
    "\n",
    "Single3-dimnesional tensor of shape  [batch_size, num_steps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_inputs = tf.one_hot(x,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(3, 10, 2) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of rnn_cell\n",
    "\n",
    "This is very similar to the ``call`` method on Tensorflow's BasicRNNCell. \n",
    "See: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1213\n",
    "\n",
    "According to their documentation:<br>\n",
    "Run the cell and add its inputs to its outputs.<br>\n",
    "\n",
    "It looks like:\n",
    "<a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\"><img src=\"https://r2rt.com/static/images/NH_VanillaRNNcell.png\" width=\"400px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Replace our function for building rnn cells"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable(name='W',shape=[NUM_CLASSES + STATE_SIZE, STATE_SIZE])\n",
    "    b = tf.get_variable(name='b',shape=[STATE_SIZE],initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "def rnn_cell(rnn_input,state):\n",
    "    with tf.variable_scope('rnn_cell',reuse=True):\n",
    "        W = tf.get_variable(name='W',shape=[NUM_CLASSES + STATE_SIZE, STATE_SIZE])\n",
    "        b = tf.get_variable(name='b',shape=[STATE_SIZE],initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "    #concat(rnn_input,state) => Prior state & Current Input on the image\n",
    "    #W, bias and tanh are pretty clear in the image\n",
    "    return tf.tanh(tf.matmul(tf.concat(values=[rnn_input,state],axis=1),W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With TF API for RNN cells → **BasicRNNCell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(STATE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api.\n",
    "See: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L1092\n",
    "\n",
    "According to their documentation:<br>\n",
    "Creates a recurrent neural network specified by RNNCell `cell`.\n",
    "\n",
    "It looks like:\n",
    "\n",
    "<a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html\"><img src=\"https://r2rt.com/static/images/NH_ComposedRNNcells.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Replace our code for adding the cells to the graph and getting the ``final_state`` and ``rnn_outputs``"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state = init_state #Initialize state (left dotted square on image)\n",
    "rnn_outputs = [] #Create a list as placeholder for the outputs (top dotted squares in image)\n",
    "\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input=rnn_input,state=state) #Create a RNN cell and store the output state\n",
    "    rnn_outputs.append(state) #Append it to the list\n",
    "final_state = rnn_outputs[-1] #The final state is the last output (top right dotted square on the image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the TF API → **dynamic_rnn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell=cell,inputs=rnn_inputs,initial_state=init_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And thats all\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions, loss, training step\n",
    "\n",
    "Predictions will be the result of **softmax** to the **logits**. **Logits** will be the result of matrix multiplication with **Wout** and **bout**.\n",
    "\n",
    "Because of the steps, instead of one, we will have several **losses**, one for each step. **Total loss** will be just the mean of every losses.\n",
    "\n",
    "As **optimizer** we'll be using the **Adagradoptimizer**, to do de backpropagation, feel free to experiment with that.\n",
    "\n",
    "---\n",
    "\n",
    "Because of the dynamic API we no longer need to do our ``for`` loops anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predictions##\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W',[STATE_SIZE,NUM_CLASSES])\n",
    "    b = tf.get_variable('b',[NUM_CLASSES],initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "#Reshape needed\n",
    "logits = tf.reshape(tf.matmul(tf.reshape(rnn_outputs,shape=[-1,STATE_SIZE]),W) + b,shape=[BATCH_SIZE,NUM_STEPS,NUM_CLASSES])\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "\n",
    "##Losses##\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "##Optimizer##\n",
    "train_step = tf.train.AdagradOptimizer(LEARNING_RATE).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(num_epochs,state_size=4):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        \n",
    "        for idx,epoch in enumerate(gen_epochs(num_epochs,BATCH_SIZE,NUM_STEPS)):\n",
    "            training_loss = 0\n",
    "            training_state = np.random.normal(size=(BATCH_SIZE,STATE_SIZE)) #Random initiate state\n",
    "        \n",
    "            print('Epoch %d'%idx)\n",
    "            \n",
    "            for step,(X,Y) in enumerate(epoch):\n",
    "                \n",
    "                feed_dict = {x:X,y:Y,init_state:training_state}\n",
    "                tr_losses,training_loss_,training_state,_ = sess.run([losses,total_loss,final_state,train_step],feed_dict)\n",
    "                training_loss += training_loss_\n",
    "                \n",
    "                if(step % 100 == 0 and step > 0):\n",
    "                    print('Average loss at step %d for last 250 steps: %.3f'%(step,training_loss/100))\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "                \n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Average loss at step 100 for last 250 steps: 0.533\n",
      "Average loss at step 200 for last 250 steps: 0.508\n",
      "Average loss at step 300 for last 250 steps: 0.504\n",
      "Epoch 1\n",
      "Average loss at step 100 for last 250 steps: 0.501\n",
      "Average loss at step 200 for last 250 steps: 0.509\n",
      "Average loss at step 300 for last 250 steps: 0.493\n",
      "Epoch 2\n",
      "Average loss at step 100 for last 250 steps: 0.494\n",
      "Average loss at step 200 for last 250 steps: 0.487\n",
      "Average loss at step 300 for last 250 steps: 0.490\n",
      "Epoch 3\n",
      "Average loss at step 100 for last 250 steps: 0.490\n",
      "Average loss at step 200 for last 250 steps: 0.472\n",
      "Average loss at step 300 for last 250 steps: 0.497\n",
      "Epoch 4\n",
      "Average loss at step 100 for last 250 steps: 0.498\n",
      "Average loss at step 200 for last 250 steps: 0.471\n",
      "Average loss at step 300 for last 250 steps: 0.475\n",
      "Epoch 5\n",
      "Average loss at step 100 for last 250 steps: 0.479\n",
      "Average loss at step 200 for last 250 steps: 0.480\n",
      "Average loss at step 300 for last 250 steps: 0.479\n",
      "Epoch 6\n",
      "Average loss at step 100 for last 250 steps: 0.473\n",
      "Average loss at step 200 for last 250 steps: 0.473\n",
      "Average loss at step 300 for last 250 steps: 0.473\n",
      "Epoch 7\n",
      "Average loss at step 100 for last 250 steps: 0.489\n",
      "Average loss at step 200 for last 250 steps: 0.475\n",
      "Average loss at step 300 for last 250 steps: 0.486\n",
      "Epoch 8\n",
      "Average loss at step 100 for last 250 steps: 0.499\n",
      "Average loss at step 200 for last 250 steps: 0.465\n",
      "Average loss at step 300 for last 250 steps: 0.460\n",
      "Epoch 9\n",
      "Average loss at step 100 for last 250 steps: 0.480\n",
      "Average loss at step 200 for last 250 steps: 0.481\n",
      "Average loss at step 300 for last 250 steps: 0.462\n"
     ]
    }
   ],
   "source": [
    "training_losses = train_network(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGJJJREFUeJzt3X20ZXV93/H3hwF0RHRURgvDxEFLaKIS0CvVotZlwkPt\nWkB9JD7UscuSroSFaVOSoU1XLLZxIhprV1gmWHFhY0WLSEZhOT4QSeOKOHd4FMjECYUwM1RGHkR0\nDDB++8fZF66XO3efw5x9zzn3vl9r3cXd++x97nffw+zP3b/fb/92qgpJkhZywKgLkCSNP8NCktTK\nsJAktTIsJEmtDAtJUivDQpLUyrCQJLUyLKQnIckdSX5l1HVIi8WwkCS1MiykIUryr5NsT3Jfkk1J\njmjWJ8lHktyT5AdJbkry4ua11ye5NckPk+xM8u9HexTSExkW0pAkeR3wAeAtwOHAncClzcsnA68B\nfh5YBbwVuLd57RPAr1XVocCLgasXsWypLweOugBpCXk7cHFVXQeQ5Dzg/iTrgEeAQ4F/BHy7qm6b\ntd8jwC8mubGq7gfuX9SqpT54ZSENzxH0riYAqKqH6F09rKmqq4E/Ai4EvpfkoiTPaDZ9I/B64M4k\n1yR55SLXLbUyLKTh2QU8f2YhySHAc4CdAFX136vqZcCL6DVHndus31JVpwPPBa4APrfIdUutDAvp\nyTsoyVNnvuid5N+d5LgkTwF+H7i2qu5I8vIk/zjJQcCPgJ8Ae5McnOTtSZ5ZVY8ADwJ7R3ZE0j4Y\nFtKTdxWwZ9bXq4H/BHweuBt4IXBms+0zgI/T64+4k17z1Iea194J3JHkQeDfAO9YpPqlvsWHH0mS\n2nhlIUlqZVhIkloZFpKkVoaFJKnVkrmD+7DDDqt169aNugxJmihbt279flWtbttuyYTFunXrmJ6e\nHnUZkjRRktzZvpXNUJKkPhgWkqRWhoUkqZVhIUlqZVhIkloZFpKkVoaFJKmVYSFJamVYSJJaGRaS\npFaGhSSplWEhSWplWEiSWhkWkqRWhoUkqZVhIUlqZVhIkloZFpKkVp2GRZJTk2xLsj3JhnleX59k\nd5Ibmq/3zHn9GUl2JvmjLuuUJC2ss2dwJ1kBXAicBOwAtiTZVFW3ztn0s1V19j7e5v3ANV3VKEnq\nT5dXFicA26vq9qp6GLgUOL3fnZO8DHge8JWO6pMk9anLsFgD3DVreUezbq43JrkpyWVJ1gIkOQD4\nMHDuQj8gyVlJppNM7969e1h1S5Lm6DIsMs+6mrP8RWBdVR0LfA24pFn/68BVVXUXC6iqi6pqqqqm\nVq9evd8FS5Lm11mfBb0ribWzlo8Eds3eoKrunbX4ceAPmu9fCbw6ya8DTwcOTvJQVT2hk1yS1L0u\nw2ILcHSSo4CdwJnA22ZvkOTwqrq7WTwNuA2gqt4+a5v1wJRBIUmj01lYVNWjSc4GNgMrgIur6pYk\n5wPTVbUJOCfJacCjwH3A+q7qkSQ9eama240wmaampmp6enrUZUjSREmytaqm2rbzDm5JUivDQpLU\nyrCQJLUyLCRJrQwLSVKrLu+zmAhXXL+TCzZvY9cDezhi1UrOPeUYzjh+vllJJGn5WtZhccX1Oznv\n8pvZ88heAHY+sIfzLr8ZwMCQpFmWdTPUBZu3PRYUM/Y8spcLNm8bUUWSNJ6WdVjsemDPQOslabla\n1mFxxKqVA62XpOVqWYfFuaccw8qDVvzMupUHreDcU44ZUUWSNJ6WdQf3TCe2o6EkaWHLOiygFxiG\ngyQtbFk3Q0mS+mNYSJJaGRaSpFaGhSSplWEhSWplWEiSWhkWkqRWhoUkqZVhIUlqZVhIkloZFpKk\nVoaFJKmVYSFJamVYSJJaGRaSpFaGhSSplWEhSWplWEiSWnUaFklOTbItyfYkG+Z5fX2S3UluaL7e\n06w/LslfJbklyU1J3tplnZKkhXX2DO4kK4ALgZOAHcCWJJuq6tY5m362qs6es+7HwL+squ8mOQLY\nmmRzVT3QVb2SpH3r8sriBGB7Vd1eVQ8DlwKn97NjVf1NVX23+X4XcA+wurNKJUkL6jIs1gB3zVre\n0ayb641NU9NlSdbOfTHJCcDBwN/O89pZSaaTTO/evXtYdUuS5ugyLDLPupqz/EVgXVUdC3wNuORn\n3iA5HPifwLur6qdPeLOqi6pqqqqmVq/2wkOSutJlWOwAZl8pHAnsmr1BVd1bVX/fLH4ceNnMa0me\nAVwJ/G5VfavDOiVJLboMiy3A0UmOSnIwcCawafYGzZXDjNOA25r1BwNfAD5VVf+7wxolSX3obDRU\nVT2a5GxgM7ACuLiqbklyPjBdVZuAc5KcBjwK3Aesb3Z/C/Aa4DlJZtatr6obuqpXkrRvqZrbjTCZ\npqamanp6etRlSNJESbK1qqbatvMObklSK8NCktTKsJAktTIsJEmtDAtJUivDQpLUyrCQJLUyLCRJ\nrQwLSVIrw0KS1MqwkCS1MiwkSa0MC0lSq86mKNdwXXH9Ti7YvI1dD+zhiFUrOfeUYzjj+PmeUitJ\nw2dY9GmUJ+srrt/JeZffzJ5H9gKw84E9nHf5zQAGhqRFYTNUH2ZO1jsf2EPx+Mn6iut3LsrPv2Dz\ntseCYsaeR/ZyweZti/LzJcmw6MOoT9a7Htgz0HpJGjbDog+jPlkfsWrlQOsladgMiz6M+mR97inH\nsPKgFT+zbuVBKzj3lGMW5edLkmHRh1GfrM84fg0feMNLWLNqJQHWrFrJB97wEju3JS0aR0P1Yeak\nPMqhq2ccv8ZwkDQyhkWfPFlLWs4Miw54A52kpcawGDJvoJO0FNnBPWSjvidDkrpgWAzZqO/JkKQu\nGBZDNup7MiSpC4bFkI36ngxJ6oId3EM2yD0ZjpqSNCkMiw70c0+Go6YkTZJOm6GSnJpkW5LtSTbM\n8/r6JLuT3NB8vWfWa+9K8t3m611d1jkKjpqSNEk6u7JIsgK4EDgJ2AFsSbKpqm6ds+lnq+rsOfs+\nG/g9YAooYGuz7/1d1bvYHDUlaZJ02Qx1ArC9qm4HSHIpcDowNyzmcwrw1aq6r9n3q8CpwGc6qnXR\nHbFqJTvnCQZHTUndsI9w/3TZDLUGuGvW8o5m3VxvTHJTksuSrB1k3yRnJZlOMr179+5h1b0oHDUl\nLZ5RP+1yKegrLJK8N8kz0vOJJNclObltt3nW1ZzlLwLrqupY4GvAJQPsS1VdVFVTVTW1evXqtsMY\nK047Li0e+wj3X7/NUP+qqj6a5BRgNfBu4JPAVxbYZwewdtbykcCu2RtU1b2zFj8O/MGsfV87Z99v\n9FnrxHAm29GxSWJ5sY9w//XbDDXzl/7rgU9W1Y3M/9f/bFuAo5McleRg4Exg08+8aXL4rMXTgNua\n7zcDJyd5VpJnASc366T9ZpPE8uPMCvuv37DYmuQr9MJic5JDgZ8utENVPQqcTe8kfxvwuaq6Jcn5\nSU5rNjsnyS1JbgTOAdY3+94HvJ9e4GwBzp/p7Jb25Yrrd3Lixqs5asOVnLjx6n2e/G2SWH7sI9x/\nqXpCV8ATN0oOAI4Dbq+qB5qhrUdW1U1dF9ivqampmp6eHnUZGpG5NzlC72QwXz/QURuufGIHGL1L\n5f+78Z93W6hGxqbH+SXZWlVTbdv122fxSuCGqvpRkncALwU+uj8FSsO00NXC3BOCw5aXJ/sI90+/\nzVAfA36c5JeA3wbuBD7VWVXSgAbpwLRJQhpcv2HxaPXaq04HPlpVHwUO7a4saTCDdGA6bFkaXL/N\nUD9Mch7wTuDVzVQeB3VXlhbDUmrDPfeUY+bts9jX1YJNEtJg+g2LtwJvo3e/xf9L8nPABd2VpSer\n3wBYarPeDjI1vKTB9TUaCiDJ84CXN4vfrqp7OqvqSXA01GAjgk7cePW8nbxrVq3kmxte13mtksZD\nv6Oh+p3u4y3At4E3A28Brk3ypv0rUcM2yP0D3tEqaRD9NkP9R+DlM1cTSVbTm8vpsq4K0+AGCQCH\nj0oaRL+joQ6Y0+x07wD7apEMMiLI4aOSBtHvCf/LSTY3T7ZbD1wJXNVdWXoyBgkAh49KGsQgHdxv\nBE6kNyvCX1TVF7osbFB2cPdMynDYSalTWur67eDuOyzGnWExHvoJgUFGbUnq1lBGQyX5YZIH5/n6\nYZIHh1euloJ+p/521ldp8iw4GqqqnNJDfet3Mj+H7S5fNj9OLkc0aWj6DQEfRLM8+dCpyWZYaGj6\nDQGH7S5PNj9ONsNCQ9NvCDhsd3my+XGy9XsHt5axftuZB5nMz1lflx9nDZhshoUWNOjstIaA9mXQ\naeQ1XgwLLWiQx5VKC+lqGnlHWC0Ow0ILsp1ZwzTsK8+l9lyWcWYHtxbkMFeNM0dYLR7DQgtymKvG\nmVe+i8ew0IIc5qpx5pXv4rHPQq0c4aRx5QirxWNYSJpYXY2w0hMZFpImmle+i8M+C0lSK8NCktTK\nZihJGiPjeke6YSFJY2Kc70jvtBkqyalJtiXZnmTDAtu9KUklmWqWD0pySZKbk9yW5Lwu65Skrl1x\n/U5O3Hg1R224khM3Xj3vQ5/G+Y70zq4skqwALgROAnYAW5Jsqqpb52x3KHAOcO2s1W8GnlJVL0ny\nNODWJJ+pqju6qldaLIM0M4xrk4QG0+8Vwzjfkd7llcUJwPaqur2qHgYuBU6fZ7v3Ax8EfjJrXQGH\nJDkQWAk8DDzYYa3Sohjk0aKDbtv2V6tGp98rhnG+I73LsFgD3DVreUez7jFJjgfWVtWX5ux7GfAj\n4G7g74APVdV9c39AkrOSTCeZ3r1791CLl7owSDNDv9v6bOvx1+8VwzjPxdZlWGSedfXYi8kBwEeA\n35pnuxOAvcARwFHAbyV5wRPerOqiqpqqqqnVq1cPp2qpQ4M0M/S77Ti3c6un3yuGcZ6LrcvRUDuA\ntbOWjwR2zVo+FHgx8I0kAP8A2JTkNOBtwJer6hHgniTfBKaA2zusV+rcII8W7XfbcW7nVs8gc1iN\n6x3pXV5ZbAGOTnJUkoOBM4FNMy9W1Q+q6rCqWldV64BvAadV1TS9pqfXpecQ4BXAX3dYq7QoBmlm\n6HfbcW7nVs84XzH0q7Mri6p6NMnZwGZgBXBxVd2S5Hxguqo2LbD7hcAnge/Qa876ZFXd1FWt0mIZ\nZOK7frd15tXJMK5XDP1KVbVvNQGmpqZqenp61GVII+EQWz1ZSbZW1VTbdt7BLQ3JKE/Yk/5X63wM\nwPFiWEhDMM7TNEwif5/jx1lnpSFw+Opw+fscP4aFNAQOXx0uf5/jx2YoaQgGuX9i1PrtCxjlHFaT\n9PtcLryykIZgnKdpmK3fqUG6msOqX5Py+1xODAuNvUmYJG9Sbrrqty+gizmsBjEpv8/lxGYojbVJ\nGhUzCcNX++0L6GIOq0FNwu9zOfHKQmPNUTHD1e/UIINMIeJ0I8uDYaGxNupRMZPQBDaIfvsCupjD\nSpPNZiiNtVGOipmkJrB+9TvfVBdzWGmyOTeUxtrcEzb0/mpdjM7OEzdePW9QrVm1km9ueF2nP1ta\nLM4NpSVhlH+1jroJTBonhoXG3qhGxXhjmPQ4O7ilfbDjVnqcVxbSPthxKz3OsJAW4I1hUo/NUJKk\nVoaFJKmVYSFJamVYSJJa2cEtSXMM+2FOS4FhIUmzLMU5wYbBZihJmsVp8ednWEjSLM4JNj/DQpJm\n8WFO8zMsJGkW5wSbnx3ckjTLJM0JtpijtgwLSZpjEuYEW+xRWzZDSdIEWuxRW52GRZJTk2xLsj3J\nhgW2e1OSSjI1a92xSf4qyS1Jbk7y1C5rlaRBXXH9Tk7ceDVHbbiSEzdezRXX71y0n73Yo7Y6a4ZK\nsgK4EDgJ2AFsSbKpqm6ds92hwDnAtbPWHQj8KfDOqroxyXOAR7qqVZIGNeqb9xb7SY5dXlmcAGyv\nqtur6mHgUuD0ebZ7P/BB4Cez1p0M3FRVNwJU1b1VtXeefSVpJEZ9895ij9rqMizWAHfNWt7RrHtM\nkuOBtVX1pTn7/jxQSTYnuS7Jb8/3A5KclWQ6yfTu3buHWbskLWjUN++dcfwaPvCGl7Bm1UoCrFm1\nkg+84SUTORoq86yrx15MDgA+AqyfZ7sDgVcBLwd+DHw9ydaq+vrPvFnVRcBFAFNTU/WEd5Gkjix2\nM9B8FnPUVpdXFjuAtbOWjwR2zVo+FHgx8I0kdwCvADY1ndw7gGuq6vtV9WPgKuClHdYqSQNZbjfv\ndRkWW4CjkxyV5GDgTGDTzItV9YOqOqyq1lXVOuBbwGlVNQ1sBo5N8rSms/ufArc+8UdI0mgsdjPQ\nqHXWDFVVjyY5m96JfwVwcVXdkuR8YLqqNi2w7/1J/pBe4BRwVVVd2VWtkvRkTMLNe8OSqqXR1D81\nNVXT09OjLkOSJkrTHzzVtp13cEuSWhkWkqRWhoUkqZVhIUlqZVhIkloZFpKkVoaFJKmVYSFJamVY\nSJJaGRaSpFaGhSSplWEhSWplWEiSWhkWkqRWhoUkqZVhIUlqZVhIkloZFpKkVoaFJKmVYSFJamVY\nSJJaGRaSpFaGhSSplWEhSWplWEiSWhkWkqRWhoUkqZVhIUlqZVhIkloZFpKkVoaFJKlVqmrUNQxF\nkt3AnfvxFocB3x9SOeNgqR0PLL1jWmrHA0vvmJbD8Ty/qla37bhkwmJ/JZmuqqlR1zEsS+14YOkd\n01I7Hlh6x+TxPM5mKElSK8NCktTKsHjcRaMuYMiW2vHA0jumpXY8sPSOyeNp2GchSWrllYUkqZVh\nIUlqtezDIsmpSbYl2Z5kw6jrGYYkdyS5OckNSaZHXc+gklyc5J4k35m17tlJvprku81/nzXKGge1\nj2N6X5Kdzed0Q5LXj7LGQSRZm+TPk9yW5JYk723WT+TntMDxTPJn9NQk305yY3NM/7lZf1SSa5vP\n6LNJDu7r/ZZzn0WSFcDfACcBO4AtwK9W1a0jLWw/JbkDmKqqibyZKMlrgIeAT1XVi5t1HwTuq6qN\nTag/q6p+Z5R1DmIfx/Q+4KGq+tAoa3sykhwOHF5V1yU5FNgKnAGsZwI/pwWO5y1M7mcU4JCqeijJ\nQcBfAu8F/h1weVVdmuSPgRur6mNt77fcryxOALZX1e1V9TBwKXD6iGta9qrqL4D75qw+Hbik+f4S\nev+QJ8Y+jmliVdXdVXVd8/0PgduANUzo57TA8Uys6nmoWTyo+SrgdcBlzfq+P6PlHhZrgLtmLe9g\nwv8HaRTwlSRbk5w16mKG5HlVdTf0/mEDzx1xPcNydpKbmmaqiWiymSvJOuB44FqWwOc053hggj+j\nJCuS3ADcA3wV+Fvggap6tNmk73Pecg+LzLNuKbTLnVhVLwX+GfAbTROIxs/HgBcCxwF3Ax8ebTmD\nS/J04PPAb1bVg6OuZ3/NczwT/RlV1d6qOg44kl5Lyi/Mt1k/77Xcw2IHsHbW8pHArhHVMjRVtav5\n7z3AF+j9TzLpvte0K8+0L98z4nr2W1V9r/nH/FPg40zY59S0g38e+HRVXd6sntjPab7jmfTPaEZV\nPQB8A3gFsCrJgc1LfZ/zlntYbAGObkYHHAycCWwacU37JckhTQcdSQ4BTga+s/BeE2ET8K7m+3cB\nfzbCWoZi5qTa+BdM0OfUdJ5+Aritqv5w1ksT+Tnt63gm/DNanWRV8/1K4Ffo9cX8OfCmZrO+P6Nl\nPRoKoBkK99+AFcDFVfVfR1zSfknyAnpXEwAHAv9r0o4pyWeA19KbTvl7wO8BVwCfA34O+DvgzVU1\nMR3G+zim19Jr3ijgDuDXZtr7x12SVwH/B7gZ+Gmz+j/Qa+efuM9pgeP5VSb3MzqWXgf2CnoXBp+r\nqvObc8SlwLOB64F3VNXft77fcg8LSVK75d4MJUnqg2EhSWplWEiSWhkWkqRWhoUkqZVhIY1Qktcm\n+dKo65DaGBaSpFaGhdSHJO9ong1wQ5I/aSZoeyjJh5Ncl+TrSVY32x6X5FvN5HNfmJl8Lsk/TPK1\n5vkC1yV5YfP2T09yWZK/TvLp5m5ikmxMcmvzPhM3RbaWFsNCapHkF4C30pug8ThgL/B24BDgumbS\nxmvo3ZUN8Cngd6rqWHp3BM+s/zRwYVX9EvBP6E1MB70ZTn8T+EXgBcCJSZ5Nb3qJFzXv81+6PUpp\nYYaF1O6XgZcBW5rpnn+Z3kn9p8Bnm23+FHhVkmcCq6rqmmb9JcBrmvm61lTVFwCq6idV9eNmm29X\n1Y5msrobgHXAg8BPgP+R5A3AzLbSSBgWUrsAl1TVcc3XMVX1vnm2W2junPmmw58xe16evcCBzfMG\nTqA3C+oZwJcHrFkaKsNCavd14E1JnguPPWf6+fT+/czM3vk24C+r6gfA/Ule3ax/J3BN82yEHUnO\naN7jKUmetq8f2DxX4ZlVdRW9JqrjujgwqV8Htm8iLW9VdWuS36X39MEDgEeA3wB+BLwoyVbgB/T6\nNaA37fMfN2FwO/DuZv07gT9Jcn7zHm9e4MceCvxZkqfSuyr5t0M+LGkgzjorPUlJHqqqp4+6Dmkx\n2AwlSWrllYUkqZVXFpKkVoaFJKmVYSFJamVYSJJaGRaSpFb/H8CZoNbMcViSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d775505780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.scatter(x=np.arange(0,len(training_losses)),y=training_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
