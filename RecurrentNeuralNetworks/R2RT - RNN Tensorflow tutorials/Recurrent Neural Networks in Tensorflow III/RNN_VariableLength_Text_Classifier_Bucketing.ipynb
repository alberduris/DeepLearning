{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Variable Length Text Classifier with Bucketing\n",
    "\n",
    "For the network in ``RNN_VariableLength_Text_Classifier.ipynb``, we used a batch_size of 256. But each example in the batch had a different length ranging from 5 to 30. As the maximum length for each batch is usually very close to 30, short sequences required a lot of padding (e.g., all sequences of length 5 in the batch are padded with up to 25 zeros).\n",
    "\n",
    "This leads to a lot of excess computation, and we can improve upon it by “bucketing” our training samples. If we select our batches such that the lengths of the samples in each batch are within, say, 5 of each other, then the amount of padding in a batch of 256 is bounded by 256 * 5 = 1280. This would make our worst case outcome more than twice as good as previous average case outcome.\n",
    "\n",
    "To take advantage of bucketing, we simply modify our DataIterator. There are many ways one might implement this, but the key point to keep in mind is that we should not “bias” the order in which different sequence lengths are sampled any more than necessary to achieve bucketing. E.g., sorting our data by sequence length might seem like a good solution, but then each epoch would be trained on short sequences before longer sequences, which could harm results.\n",
    "\n",
    "The new code is between marks like:\n",
    "\n",
    "---\n",
    "# BUCKETING\n",
    "# END BUCKETING\n",
    "---\n",
    "\n",
    "<a href=\"https://r2rt.com/recurrent-neural-networks-in-tensorflow-iii-variable-length-sequences.html#improving-training-speed-using-bucketing\">[Ref]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "\n",
    "import blogs_data #available at https://github.com/spitis/blogs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PCT_LOADED = 0.06\n",
    "\n",
    "STATE_SIZE = 64\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_bracket</th>\n",
       "      <th>string</th>\n",
       "      <th>as_numbers</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169696</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>a day later they were all headed to florida an...</td>\n",
       "      <td>[7, 94, 281, 44, 88, 37, 1172, 5, 2296, 6, 4, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>they decided that i should give the rest to hi...</td>\n",
       "      <td>[44, 305, 9, 3, 145, 227, 4, 398, 5, 70, 1841, 2]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i recommend you go online and look at some of ...</td>\n",
       "      <td>[3, 2578, 15, 71, 602, 6, 186, 35, 67, 8, 4, 6...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  gender  age_bracket  \\\n",
       "0   169696       0            2   \n",
       "1    39870       1            1   \n",
       "2    65938       0            0   \n",
       "\n",
       "                                              string  \\\n",
       "0  a day later they were all headed to florida an...   \n",
       "1  they decided that i should give the rest to hi...   \n",
       "2  i recommend you go online and look at some of ...   \n",
       "\n",
       "                                          as_numbers  length  \n",
       "0  [7, 94, 281, 44, 88, 37, 1172, 5, 2296, 6, 4, ...      16  \n",
       "1  [44, 305, 9, 3, 145, 227, 4, 398, 5, 70, 1841, 2]      12  \n",
       "2  [3, 2578, 15, 71, 602, 6, 186, 35, 67, 8, 4, 6...      17  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = blogs_data.loadBlogs().sample(frac=DATA_PCT_LOADED).reset_index(drop=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['as_numbers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73382, 18345)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab,reverse_vocab = blogs_data.loadVocab()\n",
    "train_len, test_len = math.floor(len(df)*0.8), math.floor(len(df)*0.2)\n",
    "train_len,test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df.iloc[:train_len-1]\n",
    "test = df.iloc[train_len:train_len + test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_bracket</th>\n",
       "      <th>string</th>\n",
       "      <th>as_numbers</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>google plans &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; search engine g...</td>\n",
       "      <td>[1670, 1077, 0, 0, 0, 1200, 3234, 2150, 1077, ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the only person who cares about you is a half ...</td>\n",
       "      <td>[4, 99, 211, 74, 1587, 47, 15, 14, 7, 351, 0, ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  gender  age_bracket  \\\n",
       "0    47107       0            0   \n",
       "1   148011       1            0   \n",
       "\n",
       "                                              string  \\\n",
       "0  google plans <UNK> <UNK> <UNK> search engine g...   \n",
       "1  the only person who cares about you is a half ...   \n",
       "\n",
       "                                          as_numbers  length  \n",
       "0  [1670, 1077, 0, 0, 0, 1200, 3234, 2150, 1077, ...      30  \n",
       "1  [4, 99, 211, 74, 1587, 47, 15, 14, 7, 351, 0, ...      18  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_bracket</th>\n",
       "      <th>string</th>\n",
       "      <th>as_numbers</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73382</th>\n",
       "      <td>27131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>we were so busy seeing a prospect in each that...</td>\n",
       "      <td>[32, 88, 27, 701, 550, 7, 6159, 11, 273, 9, 32...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73383</th>\n",
       "      <td>156099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;UNK&gt; does not &lt;UNK&gt; war ’s &lt;UNK&gt; with its mor...</td>\n",
       "      <td>[0, 149, 34, 0, 482, 206, 0, 26, 132, 6160, 18...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  gender  age_bracket  \\\n",
       "73382    27131       1            1   \n",
       "73383   156099       1            1   \n",
       "\n",
       "                                                  string  \\\n",
       "73382  we were so busy seeing a prospect in each that...   \n",
       "73383  <UNK> does not <UNK> war ’s <UNK> with its mor...   \n",
       "\n",
       "                                              as_numbers  length  \n",
       "73382  [32, 88, 27, 701, 550, 7, 6159, 11, 273, 9, 32...      17  \n",
       "73383  [0, 149, 34, 0, 482, 206, 0, 26, 132, 6160, 18...      24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data\n",
    "\n",
    "### Data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleDataIterator():\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.size = len(self.df)\n",
    "        self.epochs = 0\n",
    "        self.shuffle()\n",
    "        \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.cursor = 0\n",
    "        \n",
    "    def next_batch(self,n):\n",
    "        if(self.cursor+n-1 > self.size):\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.iloc[self.cursor:self.cursor+n]\n",
    "        self.cursor += n\n",
    "        return res['as_numbers'],res['gender']*3 + res['age_bracket'],res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " 0    [41, 30, 2637, 26, 19, 1, 6, 3, 123, 59, 231, ...\n",
      "1       [0, 3, 64, 29, 14, 90, 5, 30, 7, 506, 1021, 2]\n",
      "2       [43, 4, 1257, 60, 30, 124, 40, 106, 29, 2, 39]\n",
      "Name: as_numbers, dtype: object\n",
      "\n",
      "Target values\n",
      " 0    1\n",
      "1    4\n",
      "2    2\n",
      "dtype: int64\n",
      "\n",
      "Sequence lengths\n",
      " 0    17\n",
      "1    12\n",
      "2    11\n",
      "Name: length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = SimpleDataIterator(train)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n', d[0], end='\\n\\n')\n",
    "print('Target values\\n', d[1], end='\\n\\n')\n",
    "print('Sequence lengths\\n', d[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# BUCKETING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BucketedDataIterator(SimpleDataIterator):\n",
    "    \n",
    "    def __init__(self,df,num_buckets=5):\n",
    "        df = df.sort_values('length').reset_index(drop=True)\n",
    "        self.size = len(df) // num_buckets\n",
    "        self.dfs = []\n",
    "        for bucket in range(num_buckets):\n",
    "            self.dfs.append(df.iloc[bucket*self.size:(bucket+1)*self.size - 1])\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "        #cursor[i] will be the cursor for the ith bucket\n",
    "        self.cursor = np.array([0] * num_buckets)\n",
    "        self.shuffle()\n",
    "        self.epochs = 0\n",
    "        \n",
    "    def shuffle(self):\n",
    "        #sorts dataframe by sequence length, but keeps it random within the same length\n",
    "        for i in range(self.num_buckets):\n",
    "            self.dfs[i] = self.dfs[i].sample(frac=1).reset_index(drop=True)\n",
    "            self.cursor[i] = 0\n",
    "    \n",
    "    def next_batch(self,n):\n",
    "        \n",
    "        if(np.any(self.cursor+n+1 > self.size)):\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        \n",
    "        i = np.random.randint(0,self.num_buckets)\n",
    "    \n",
    "        res = self.dfs[i].iloc[self.cursor[i]:self.cursor[i]+n]\n",
    "        self.cursor[i] += n\n",
    "        \n",
    "        #Pad sequences with 0s so they are all the same length\n",
    "        maxlen = max(res['length'])\n",
    "        x = np.zeros([n,maxlen],dtype=np.int32)\n",
    "        for i,x_i in enumerate(x):\n",
    "            x_i[:res['length'].values[i]] = res['as_numbers'].values[i]\n",
    "        \n",
    "        return x,res['gender']*3 + res['age_bracket'], res['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences\n",
      " [[   3  123 3131  222   46   90    5  586   35    0   49 4977    2    8\n",
      "  2050    2    0    0]\n",
      " [ 973    8  493 2553   10   17   69  486   10   80  113  133   16 4420\n",
      "     6 2530    2    0]\n",
      " [  32   42   11 4382 6975    6   57 5130  624    1 1883    1   10   14\n",
      "     7  173  192    2]]\n",
      "\n",
      "Target sequences\n",
      " 0    3\n",
      "1    3\n",
      "2    5\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = BucketedDataIterator(train)\n",
    "d = data.next_batch(3)\n",
    "print('Input sequences\\n',d[0],end='\\n\\n')\n",
    "print('Target sequences\\n',d[1],end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END BUCKETING\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "def build_graph(vocab_size = len(vocab), state_size = 64, batch_size = 256, num_classes = 6):\n",
    "    \n",
    "    reset_graph()\n",
    "    \n",
    "    #Placeholders\n",
    "    x = tf.placeholder(tf.int32,[batch_size,None]) #[batch_size, num_steps]\n",
    "    seqlen = tf.placeholder(tf.int32,[batch_size])\n",
    "    y = tf.placeholder(tf.int32,[batch_size])\n",
    "    keep_prob = tf.placeholder(1.0,name='keep_prob')\n",
    "    \n",
    "    #Embedding layer\n",
    "    embeddings = tf.get_variable('embedding_matrix',[vocab_size,state_size])\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings,x)\n",
    "    \n",
    "    #RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(state_size)\n",
    "    init_state = tf.get_variable('init_state',[1,state_size],initializer=tf.constant_initializer(0.0))\n",
    "    init_state = tf.tile(init_state,[batch_size,1])\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell,rnn_inputs,sequence_length=seqlen,initial_state=init_state)\n",
    "    rnn_outputs = tf.nn.dropout(rnn_outputs,keep_prob) #Dropout\n",
    "    \n",
    "    #Last revelant output\n",
    "    last_rnn_output = tf.gather_nd(rnn_outputs,tf.stack([tf.range(batch_size),seqlen-1],axis=1))\n",
    "    \n",
    "    #Softmax layer - Prediction\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W',[state_size,num_classes])\n",
    "        b = tf.get_variable('b',[num_classes],initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(last_rnn_output,W) + b\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct = tf.equal(tf.cast(tf.argmax(preds,1),tf.int32),y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "    ret_dict = {'x':x,'seqlen':seqlen,'y':y,'dropout':keep_prob,'loss':loss,'ts':train_step,'preds':preds,'accuracy':accuracy}\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(graph,batch_size = 256, num_epochs = 10, iterator=BucketedDataIterator):\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tr = iterator(train)\n",
    "        te = iterator(test)\n",
    "        \n",
    "        step,accuracy = 0,0\n",
    "        tr_losses,te_losses = [],[]\n",
    "        current_epoch = 0\n",
    "        \n",
    "        while current_epoch < num_epochs:\n",
    "            step += 1\n",
    "            batch = tr.next_batch(batch_size)\n",
    "            feed = {g['x']:batch[0],g['y']:batch[1],g['seqlen']:batch[2],g['dropout']:0.6}\n",
    "            \n",
    "            accuracy_,_ = sess.run([g['accuracy'],g['ts']],feed_dict = feed)\n",
    "            accuracy += accuracy_\n",
    "            \n",
    "            if(tr.epochs > current_epoch):\n",
    "                current_epoch += 1\n",
    "                tr_losses.append(accuracy/step)\n",
    "                step,accuracy = 0,0\n",
    "                \n",
    "                #eval test set\n",
    "                te_epoch = te.epochs\n",
    "                while (te.epochs == te_epoch):\n",
    "                    step =+ 1\n",
    "                    batch = te.next_batch(batch_size)\n",
    "                    feed = {g['x']:batch[0],g['y']:batch[1],g['seqlen']:batch[2],g['dropout']:1.0}\n",
    "                    accuracy_ = sess.run([g['accuracy']],feed_dict = feed)[0]\n",
    "                    accuracy += accuracy_\n",
    "                    \n",
    "                te_losses.append(accuracy/step)\n",
    "                step,accuracy = 0,0\n",
    "                print('Accuracy after epoch',current_epoch,\" - tr:\", tr_losses[-1],\" -te:\", te_losses[-1])\n",
    "                \n",
    "    return tr_losses,te_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = build_graph(state_size=STATE_SIZE,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 1  - tr: 0.226151315789  -te: 16.52734375\n",
      "Accuracy after epoch 2  - tr: 0.250947960251  -te: 14.78125\n",
      "Accuracy after epoch 3  - tr: 0.298364542802  -te: 18.37109375\n",
      "Accuracy after epoch 4  - tr: 0.310604079498  -te: 18.13671875\n",
      "Accuracy after epoch 5  - tr: 0.317354210251  -te: 12.8359375\n",
      "Accuracy after epoch 6  - tr: 0.323270789749  -te: 13.93359375\n",
      "Accuracy after epoch 7  - tr: 0.327715355805  -te: 13.06640625\n",
      "Accuracy after epoch 8  - tr: 0.337642840485  -te: 15.76953125\n",
      "Accuracy after epoch 9  - tr: 0.344046875  -te: 15.80078125\n",
      "Accuracy after epoch 10  - tr: 0.352512184633  -te: 14.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.22615131578947367,\n",
       "  0.25094796025104604,\n",
       "  0.29836454280155644,\n",
       "  0.31060407949790797,\n",
       "  0.31735421025104604,\n",
       "  0.32327078974895396,\n",
       "  0.32771535580524347,\n",
       "  0.33764284048507465,\n",
       "  0.34404687499999997,\n",
       "  0.35251218463302753],\n",
       " [16.52734375,\n",
       "  14.78125,\n",
       "  18.37109375,\n",
       "  18.13671875,\n",
       "  12.8359375,\n",
       "  13.93359375,\n",
       "  13.06640625,\n",
       "  15.76953125,\n",
       "  15.80078125,\n",
       "  14.1875])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph(g,batch_size=BATCH_SIZE,num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
